{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing functionality\n",
    "https://github.com/HzFu/EyeQ/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img(img):\n",
    "    img = cv2.resize(img, (0,0), fx = 0.5, fy = 0.5) # resize to half\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "    img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX) # normalize to standard range for 8-bit grayscale\n",
    "    return img\n",
    "\n",
    "def find_mask(img):\n",
    "    \"\"\"Finds the approximate of the mask in the image.\n",
    "    Args:\n",
    "        img (array): retina image in grayscale\n",
    "    Returns:\n",
    "        array: mask approximate\n",
    "    \"\"\"\n",
    "    th = np.mean(img)/3-5\n",
    "    _, mask = cv2.threshold(img, max(0,th), 1, cv2.THRESH_BINARY) # mask of 0s and 1s using computed threshold if positive\n",
    "    nn_mask = np.zeros((mask.shape[0]+2,mask.shape[1]+2),np.uint8) # 2px larger mask to prevent floodFill bleeding\n",
    "    new_mask = (1-mask).astype(np.uint8) # reverted mask\n",
    "    _,new_mask,_,_ = cv2.floodFill(new_mask, nn_mask, (0,0), (0), cv2.FLOODFILL_MASK_ONLY)\n",
    "    _,new_mask,_,_ = cv2.floodFill(new_mask, nn_mask, (new_mask.shape[1]-1,new_mask.shape[0]-1), (0), cv2.FLOODFILL_MASK_ONLY)\n",
    "    mask = mask + new_mask # combine the two masks\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20,20))\n",
    "    mask = cv2.erode(mask, kernel) # use erosion and dilation to remove noise\n",
    "    mask = cv2.dilate(mask, kernel)\n",
    "    return mask\n",
    "\n",
    "def get_center(mask):\n",
    "    \"\"\"Find center coordinates of the circular region of retina.\n",
    "    Args:\n",
    "        mask (array): mask approximate\n",
    "    Returns:\n",
    "        array: x and y coordinates of the circle's center\n",
    "    \"\"\"\n",
    "    center = np.array([0,0])\n",
    "    x=mask.sum(axis=1)\n",
    "    center[0]=np.where(x>x.max()*0.95)[0].mean().astype(int)\n",
    "    x=mask.sum(axis=0)\n",
    "    center[1]=np.where(x>x.max()*0.95)[0].mean().astype(int)\n",
    "    return center\n",
    "\n",
    "def get_radius(mask, center):\n",
    "    \"\"\"Find radius of the circular region of retina.\n",
    "    Args:\n",
    "        mask (array): mask approximate\n",
    "        center (array): circle's center coordinates\n",
    "    Returns:\n",
    "        number: radius of the circular region of retina\n",
    "    \"\"\"\n",
    "    mask=mask.astype(np.uint8)\n",
    "    ksize=max(mask.shape[1]//400*2+1,3)\n",
    "    kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(ksize,ksize))\n",
    "    mask=cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, kernel)\n",
    "    index=np.where(mask>0)\n",
    "    d_int=np.sqrt((index[0]-center[0])**2+(index[1]-center[1])**2)\n",
    "    b_count=np.bincount(np.ceil(d_int).astype(int))\n",
    "    radius=np.where(b_count>b_count.max()*0.995)[0].max()\n",
    "    return int(radius * 2) # multiply by 2 to account for downsizing\n",
    "\n",
    "def get_bbox(center, radius, img_shape):\n",
    "    \"\"\"Get bounding box of the circular region of retina.\n",
    "    Args:\n",
    "        center (array): center coordinates of the circular region of retina\n",
    "        radius (number): radius of the circular region of retina\n",
    "    Returns:\n",
    "        tuple: coordinates of the bounding box top left corner, height, and width\n",
    "    \"\"\"\n",
    "    s_h = max(0, int(center[0] - radius)) # y coord of the top left corner (ensure positive)\n",
    "    s_w = max(0, int(center[1] - radius)) # x coord of the top left corner (ensure positive)\n",
    "    # bbox info containing: starting height, starting width, height, width\n",
    "    return (s_h, s_w, min(img_shape[0]-s_h, 2*radius), min(img_shape[1]-s_w, 2*radius))\n",
    "\n",
    "def get_mask(center, radius, img_shape):\n",
    "    \"\"\"Get mask of the circular region of retina.\n",
    "    Args:\n",
    "        center (array): center coordinates of the circular region of retina\n",
    "        radius (number): radius of the circular region of retina\n",
    "        img_shape (array): shape of the image\n",
    "    Returns:\n",
    "        array: mask of the circular region of retina\n",
    "    \"\"\"\n",
    "    center_mask=np.zeros(shape=img_shape).astype('uint8')\n",
    "    center = center[::-1]\n",
    "    center_mask=cv2.circle(center_mask,center,radius,(1),-1)\n",
    "    return center_mask\n",
    "\n",
    "def apply_mask(img, mask):\n",
    "    \"\"\"Apply mask to retina image.\n",
    "    Args:\n",
    "        img (array): retina image in grayscale\n",
    "        mask (array): mask of the circular region of retina\n",
    "    Returns:\n",
    "        array: retina image with mask applied\n",
    "    \"\"\"\n",
    "    img[mask<=0,...]=0\n",
    "    return img\n",
    "\n",
    "def crop(img, bbox):\n",
    "    \"\"\"Crop retina image based on bounding box.\n",
    "    Args:\n",
    "        img (array): retina image\n",
    "        bbox (tuple): coordinates of the bounding box top left corner, height, and width\n",
    "    Returns:\n",
    "        array: cropped retina image\n",
    "    \"\"\"\n",
    "    top = bbox[0]\n",
    "    bottom = bbox[0] + bbox[2]\n",
    "    left = bbox[1]\n",
    "    right = bbox[1] + bbox[3]\n",
    "    img = img[top:bottom,left:right]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir(dir):\n",
    "    os.path.normpath(dir)\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def preprocess(in_path, out_path):\n",
    "    unsuc_preprocess = []\n",
    "    for img_path in glob.iglob(f'{in_path}/*.JPG'):\n",
    "        # if Path(img_path).exists():\n",
    "        #     continue\n",
    "        img = cv2.imread(img_path) # BGR\n",
    "        try:\n",
    "            img_gs = prepare_img(img)\n",
    "            approx_mask = find_mask(img_gs) # find mask approximation for calculations\n",
    "            center = get_center(approx_mask)\n",
    "            radius = get_radius(approx_mask, center)\n",
    "            center = center * 2 # multiply by 2 to account for downsizing\n",
    "            bbox = get_bbox(center, radius, img.shape[0:2])\n",
    "            mask = get_mask(center, radius, img.shape[0:2])\n",
    "            img = apply_mask(img, mask)\n",
    "            img = crop(img, bbox)\n",
    "        except:\n",
    "            unsuc_preprocess.append(img_path)\n",
    "            continue\n",
    "        save_path = f'{out_path}/{img_path.split(\"/\")[-1]}'\n",
    "        cv2.imwrite(save_path, img)\n",
    "    return unsuc_preprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the StraDeSetB to later use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dir('./STRaDeSetB_preprocessed')\n",
    "get_dir('./STRaDeSetB_preprocessed/Failure_cases')\n",
    "unsuc_preprocess_B = []\n",
    "unsuc_preprocess_B.append(preprocess('./STRaDeSetB', './STRaDeSetB_preprocessed'))\n",
    "unsuc_preprocess_B.append(preprocess('./STRaDeSetB/Failure_cases', './STRaDeSetB_preprocessed/Failure_cases'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_gradmap(img):\n",
    "    grad_x = cv2.Sobel(img, cv2.CV_16S, 1, 0)\n",
    "    grad_y = cv2.Sobel(img, cv2.CV_16S, 0, 1)\n",
    "    abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
    "    abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
    "    grad = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
    "    return grad\n",
    "\n",
    "def compute_features(img):\n",
    "    rows,cols,_ = img.shape\n",
    "    img_gs = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "    O = sobel_gradmap(img_gs)\n",
    "    img_lp_3 = cv2.blur(img_gs,(3,3))\n",
    "    L1 = sobel_gradmap(img_lp_3)\n",
    "    img_lp_5 = cv2.blur(img_gs,(5,5))\n",
    "    L2 = sobel_gradmap(img_lp_5)\n",
    "    # Compute focus measures\n",
    "    FM1 = sum(O)/(rows*cols)\n",
    "    FM2 = FM1 - sum(L1)/(rows*cols)\n",
    "    FM3 = sum(L1)/(rows*cols) - sum(L2)/(rows*cols)\n",
    "    return FM1, FM2, FM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM1_all = []\n",
    "FM2_all = []\n",
    "FM3_all = []\n",
    "labels = []\n",
    "for img_path in glob.iglob(f'./STRaDeSetB_preprocessed/*.JPG'):\n",
    "    img = cv2.imread(img_path) # BGR\n",
    "    FM1, FM2, FM3 = compute_features(img)\n",
    "    FM1_all.append(FM1)\n",
    "    FM2_all.append(FM2)\n",
    "    FM3_all.append(FM3)\n",
    "    labels.append('Usable')\n",
    "\n",
    "for img_path in glob.iglob(f'./STRaDeSetB_preprocessed/Failure_cases/*.JPG'):\n",
    "    img = cv2.imread(img_path) # BGR\n",
    "    FM1, FM2, FM3 = compute_features(img)\n",
    "    FM1_all.append(FM1)\n",
    "    FM2_all.append(FM2)\n",
    "    FM3_all.append(FM3)\n",
    "    labels.append('Usable')\n",
    "    \n",
    "blur_data = pd.DataFrame({'FM1': FM1_all, 'FM2': FM2_all, 'FM3': FM3_all, 'label': labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
